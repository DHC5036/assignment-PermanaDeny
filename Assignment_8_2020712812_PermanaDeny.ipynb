{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DHC_Assignment-8_2020712812.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBIn7_FppVuI"
      },
      "source": [
        "# Q1.\n",
        "Please\n",
        "describe your thoughts on the development of modern\n",
        "CNN architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WLhzlLppepG"
      },
      "source": [
        "Recent modern CNN architecture applies several type of bottlenect, such as residual, concatenation, skip connection, or combined of them. Together with deep layer and complex architecture.\n",
        "\n",
        "However, the backbone and the concept remains the same by filter sharing to enhance the benefit of inductive bias. The more complex and deep architecture is no more than to learnn the feature in detail without severe high error (in ResNet by residual connection), avoid explode or vanishing gradient (in DenseNet by accessing previous layer through skip connection & concatenation).\n",
        "\n",
        "The next challenge in modern CNN is that the behaviour in inductive bias does not perform well in very large data training set. Therefore, the next development of these CNN is to address the very large data training set."
      ]
    }
  ]
}